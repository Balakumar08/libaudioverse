[[basics]]
== Basic Concepts of Libaudioverse

In order to begin using Libaudioverse's 3d components, it is not necessary to fully understand this section.
For a gentler and much more hands-on introduction, see the tutorials.

[[basics-object-types]]
=== Nodes, Simulations, and Buffers

Libaudioverse has three main types of object:

- The simulation represents a collection of nodes and mixes audio.
- Nodes process or produce audio.
- Buffers hold chunks of audio data.

Each of these is discussed below.

[[basics-simulation]]
==== The Simulation

The simulation is the object which deserves most discussion, hence the length of this section.

The simulation is the main entry point to Libaudioverse.
When created, the simulation fixes the sampling rate of all nodes that use it.

Every simulation has two key parameters: the sampling rate and the block size.

The sampling rate is exactly what it sounds like.  When in doubt, use 44100, as this is sufficient for most purposes.

Libaudioverse processes audio in blocks.
The block size is the size of this block.
In effect, the block size is the number of samples for which any property values are fixed; properties are described below.
When the simulation has an associated output device, the block size is the number of frames of audio that will be submitted to the sound card at once.
Otherwise, it is the number of frames of audio returned by a call to `Lav_getBlock`.

See <<basics-audio-output,the section on outputting audio>> for information about associating the simulation to an audio output device.

When making multiple calls to change aspects of audio, it is possible for the user to hear intermediate changes.
This occurs because Libaudioverse might decide to process a block between them.
It is therefore possible to treat the simulation like a lock, preventing all threads save the current one from accessing this simulation and its nodes.
This includes Libaudioverse's internal threads for mixing.
In the C API, this is available through `Lav_simulationLock` and `Lav_simulationUnlock`.
For other languages, this is bound in the safest way possible.
For example, Python only allows use of this feature via with blocks.
This *is* a lock, and should be treated as such.

Finally, simulations provide the ability to execute code in the audio thread.
This allows you to write code that can update the nodes you are using without ever missing a block.
This is called the block callback.
It receives the simulation and the simulation's current time as parameters.
because it is running in the audio thread, this callback should try its best not to block.
Unlike some other audio libraries, blocking here is perfectly fine, but it will slow down audio mixing.
In addition, you are executing inside the critical section of the audio thread, so other threads of your application that may need to access this simulation will not be able to make progress.
It is not only safe to call Libaudioverse functions, but expected.
This function should act exactly as though it is being executed between calls to `Lav_simulationLock` and `Lav_simulationUnlock`.
This is the most complicated way to write code that drives Libaudioverse.
This callback exists for those applications where the greatest concern is on precise, sample-accurate  timing.

[[basics-nodes]]
==== Nodes

Nodes process audio and are composed of three main components: inputs, outputs, and properties.
most of the explanation of nodes is in other subsections.
Every node will run at most once per block, as described <<basics-audio-processing,here>>.
The specifics of properties are also discussed in a dedicated section, <<basics-properties,namely this one>>.

The relationship between inputs and outputs is many-to-many, acting as though every input is a small mixer.
It is therefore possible to have one node feed the input of many others, or to add nodes together by connecting them to the same input.
An example of the former is feeding a file through 4 filters in parallel;
an example of the latter is additive synthesis, a technique whereby sounds are made by adding other sounds together (typically sine waves).

While properties are discussed later, one deserves special mention here. Every node has a state, either playing, always playing, or paused.  The specific meanings of these are discussed below alongside the audio algorithm, but references to a node's state refer to this property.

Finally, inputs and outputs have channel counts associated with them.  So long as you are working with standard channel counts, Libaudioverse will "do the right thing" and upmix/downmix your audio appropriately.
This upmixing/downmixing is described in <<basics-audio-output,the section on audio output>>.

[[basics-buffers]]
==== Buffers

Buffers are the simplest Libaudioverse object: they hold audio data.
This data can come from anywhere and be at any sampling rate.
When the buffer's data is set, the data in it is resampled.

Buffers are intended to allow many copies of the same data to be in use simultaneously.
The use of the same buffer in multiple places takes only the resources of the node, not also the buffer.
Due to the resampling, buffers are not ideal for streaming; if you need streaming, use a streaming file node, pull node or push node.

[[basics-properties]]
=== Properties

Every node can have any number of properties.
To find out specifically which properties a specific node of interest has, see the node reference.

The purpose of a property is to hold a value.
By abstracting the logic of getting and setting values behind them, properties allow Libaudioverse to pull off a number of tricks: introspection and high-quality language binding among them.

There are two broad categories of properties: k-rate and a-rate.
These terms are borrowed from other systems similar to Libaudioverse.
A k-rate property is evaluated at the beginning of a block and not read again until the next block;
an a-rate property is read every sample.
Only float and double properties can be a-rate.

In addition, the following types of properties are present in Libaudioverse:

- Boolean: Holds 0 or 1.  In the C API, this is manipulated using the functions for int properties.
- Int: holds a 32-bit integer.
- Float: Holds a 32-bit floating point value.
- Double: Holds a64-bit double.
- Buffer: Holds a reference to a buffer.
- Float3: Holds a vector of 3 floats, primarily for position in the 3D audio components of this library.  All 3 components must be updated at once.
- Float6: Holds a vector of 6 floats, also for use primarily by the 3D components.  All 6 components must be updated at once.
- Int array: Holds an array of integers with limits on its length.
- Float array: Holds an array of floats with limits on its length.
- String: A string.

Of these, float and double properties need further discussion.
A float or double property, hereafter an automatable property, has a couple extra features.

The first of these is that it is possible to connect nodes to automatable properties, in much the same way that one connects nodes to other nodes.
When this happens, the audio of all connected nodes is downmixed to mono, added, and used to help contribute to the value of the property.

The second feature that automatable properties support is automators.
These are borrowed directly from Web Audio.
An automator moves the value of a property according to a specific instruction.  The current automators are as follows:

- Linear ramp to value: moves the property to a specific value by a specific time.

In the various programming language bindings, these are found on the classes which represent the properties themselves.
For example, in Python, `mysine.frequency.linear_ramp_to_value(1.0, 500.0)` will move the frequency of the sine node from where it is now to 500.0 HZ over 5 seconds.

Unlike node connections, changing the value of or resetting an automatable property will cancel all automators.

To be more formal, the value of an automatable property for time `t` where `t` is relative to the node's current time is computed as follows:

- If the property is a k-rate property, adjust `t` to the beginning of the block.
- Let the intrinsic value be the value of the property or, if the property has automators scheduled, the value of those automators at `t`.
- let the node value be the value of all connected nodes at `t`, summed.
- The value of the property is the sum of the intrinsic and node values.

[[basics-node-processing]]
=== Node Processing and Connections

Simulations are like nodes with 1 input that cannot be accessed through the usual functions.
Nodes have a function, namely `Lav_nodeConnectSimulation`, which connects a specific output to the internal input connection of the simulation passed to the node when it was created.

Both nodes and simulations have their own time, measured relative to how many blocks of audio have been processed.
This is used with the automation API in order to determine the values of properties.
When a time is not relative to realtime, this manual will make a point of indicating that this is the case.
It is not possible to query this time.

Nodes also have a state.
Two of these, stopped and always playing, are simple.
If a node is stopped, time does not advance for it.
If a node is always playing, time always advances for it at the same rate that time is advancing for the simulation.
The final state is playing, which is slightly more complex.
While these concepts can be explained in English, this is a case where pseudocode is worth a thousand words:

....
function process(node):
    if node.state == "stopped" then return
    for i in get_dependencies(node):
        process(i)
    node.tick()

function audio_algorithm(simulation):
    for i in simulation.connected_nodes:
        process(i)
    for i in simulation.all_nodes if i.state=="always playing":
        process(i)
....

Libaudioverse will prevent you from causing cyclic dependencies.

If you wish to escape this algorithm, set every node to the always playing state after creating it.
That said, this algorithm usually does what you want.
Consider the following sequence:

- You want to build a structure of nodes representing an instrument.
- You create each node, set its state to always playing, and connect it to other nodes.
- In the middle of this process, a block advances.
- Some of these nodes advance, but the rest do not.
- The instrument gets returned, and stored temporarily.
- Time advances some more.
- You connect it to the simulation.

At which point you are playing a half-played instrument.
If the default state is always playing, the same problem arises: time might advance between the node's creation and you changing it to the playing state.
It can also happen for file nodes: time can advance by a block before you get the file node connected to the simulation, or whereever else it is going.
In garbage collected languages, there is one additional implication of always playing: if a node is no longer needed but has yet to be garbage collected, it will still take up CPU resources.
While this is not a big deal for, say, the amplitude panner, some nodes like the HRTF panner and the feedback delay network take up large amounts of CPU resources.

[[basics-audio-output]]
=== Audio Output and Mixing

Libaudioverse represents the audio device as a regular simulation with an associated output device.
When an output device is associated, it becomes impossible for a program to read the simulation directly.
Instead, an internal thread mixes audio from the simulation and passes it to the sound card.

Output devices are represented by a device index, an integer ranging from -1 to one less than the maximum number of devices on the system.
-1 is the default audio device.
Additionally, if possible on the platform in question, -1 will attempt to follow the default audio device if it changes.

Libaudioverse does provide some query functions to get information on devices, but this information is not reliable on any platform I am currently aware of: devices that lie to the system are common, as is backward compatibility hacks.
Good examples include WinMM on Windows (more than happy to claim 7.1 surround sound on stereo headphones)
and the Logitech G930 headphones, which always show up as surround sound even when switched to stereo by a physical switch on the device.

This essentially means that there is no other option but asking your user what their audio configuration is.
To deal with the uncertainty, use a multipanner or the 3D simulation components for easy switching.
The only good default for panners is stereo with no HRTF, as this will be upmixed to surround sound systems by the OS in most cases.

==== Automatic Mixing

Libaudioverse supports the ability to automatically upmix and downmix audio.
It understands the following formats:

- Mono.  Specified with channel value 1.
- Stereo.  2 channels.  Channel 0 is left, channel 1 is right.
- 5.1 surround sound.  6 channels.  Front left, front right, center, LFE, rear left, rear right.
- 7.1.  8 channels.  Front left, front right, center, lfe, rear left, rear right, side left, side right.

Any connection made between an input and an output with these channel values will cause audio to be remixed accordingly.
In other configurations, one of the following two cases happens:

- If the output has more channels than the input, additional channels are dropped.
- If the input has more channels than the output, additional channels are considered to be zero.

Simulations do not have an intrinsic channel count.
Instead, this is a parameter to either `Lav_getBlock` or `Lav_simulationSetOutputDevice`.
All nodes which are connected to the simulation will be remixed in the same manner as any other input-output connection,
but the channel count used is the one specified to either of these functions.
