[[tutorials]]
== Tutorials

The following is a collection of tutorials using Python, presented heree because the rest of this manual can be somewhat dense.
if you are using C or another binding, the translation should be clear in most cases.
C is describedin this manual.
For other languages, your bindings should indicate how specific things work.

These tutorials start with code examples and work their way to design patterns and informal descriptions of Libaudioverse concepts.
Reading all of this section is not necessary, as later tutorials may discuss things you do not need at the moment.
It is suggested that you treat this section like a recipe book: read it until you get the idea, and then return when you need to know how specific things work.

=== Playing a Sine Wave

The following is the simplest Libaudioverse program that does something, namely output a sine wave for 5 seconds.
A full explanation follows.

....
import libaudioverse
import time

libaudioverse.initialize()

#Create a simulation using the defaults.
simulation = libaudioverse.Simulation()

#A sine node synthesizes a sine wave:
sine = libaudioverse.SineNode(simulation)

#In order to output, we connect to the simulation.
sine.connect_simulation(output = 0)

#The simulation will play once it has been told to use a specific output device.
simulation.set_output_device(-1)

time.sleep(5.0)
libaudioverse.shutdown()
....

Most programs using Libaudioverse look similar to this pattern, though they usually involve more nodes.

The first and last lines initialize and shut down Libaudioverse.
Your program should always have these without fail.
After Libaudioverse is shut down, accessing objects created from it is undefined behavior.

After initialization, we create a simulation, the gateway to Libaudioverse functionality.
Every other object in the library requires  one when it is created;
we refer to such simulations as the object's simulation.
It is not possible to change the object's simulation after it is created, but most applications will only create one simulation anyway.

Simulations fix the sample rate and the block size.
The block size is the number of samples to be synthesized at once.
While Libaudioverse is synthesizing a block of samples, it is not possible for your application to make changes that involve the simulation for which samples are being synthesized.

Next, we create a sine node.
Nodes are responsible for producing or modifying audio.
They have inputs, outputs, and properties.
Inputs and properties will be explained later.

In order for us to hear audio, or indeed for the sine node to do anything at all, we need to send its output somewhere.
We refer to outputs with numeric indices.
In the case of sine nodes, there is only one output, namely the syntehsized sine wave.

In order to actually hear audio, some outputs must connect to the simulation.
Simulations pull on all connected nodes, causing them to process audio.
The purpose of `connect_simulation` is to connect an output to the simulation, causing the node in question to be asked for audio by the simulation directly.
All outputs which are connected to the simulation are added together and produced as its output.
It is possible to make changes after the simulation has an output device.
Assigning the output device after all setup is a common characteristic of demos, but real programs are obviously much more complicated.

Finally, there are a number of ways to get output from the simulation.
We can ask for a block of samples, write audio directly to files, or send it to the sound card.
We use the last option here.
The purpose of `set_output_device` is to tell the simulation which output device to use.
The index `-1` specifies that we wish to use the default audio device.
There are other parameters to this function, namely the channels and mixahead, but once again the defaults are good enough.

=== Sweeping Sine Waves with properties

The second most important concept of Libaudioverse is properties.
Properties are responsible for controlling aspects of audio, for example the frequency of the above sine wave.
The following snippet demonstrates sweeping the sine wave in the above example from 0 to 1000 HZ, as well as changing its volume.

....
#Recall that Python omits the last value.
for i in xrange(0, 1010, 10):
    sine.mul.value = i/1000.0
    sine.frequency.value = i
    time.sleep(0.02)
....

There are a number of various operations which may be performed on a property.
Setting and getting the value are the most obvious.
Others include resetting it, querying the range, and scheduling changes to happen in the future.
To that end, languages with classes will often hide the property behind an additional class.
This is the case in Python, which requires syntax as in the example above.

There is a better way to handle this example.  We will revisit the above loop shortly.

=== Buffers and Playing Files

The following loops a file until enter is pressed.

....
import libaudioverse

libaudioverse.initialize()

simulation = libaudioverse.Simulation()

print "Enter a path to a sound file."
path = raw_input()

buffer=libaudioverse.Buffer(simulation)
buffer.load_from_file(path)
buffer_player=libaudioverse.BufferNode(simulation)
buffer_player.buffer.value = buffer
buffer_player.looping.value = True

#Connect the buffer.
buffer_player.connect_simulation(0)

#The simulation will play once it has been told to use a specific output device.
simulation.set_output_device(-1)

print "Press enter to exit."
raw_input()
libaudioverse.shutdown()
....

Buffers hold audio data and, most importantly, allow for sharing.
If we were simpply to have a file node, something which was the case in an early stage of development, playing the same file multiple times would result in loading it into memory multiple times.
A buffer representing some data can be used with as many buffer nodes as desired without using more memory.

Another disadvantage of loading files directly is that the file will need to be resampled multiple times, once for each duplicate load.
Buffers avoid this by resampling when data is loaded into them.


Finally, it is possible to load any data you wish into a buffer.
The `load_from_file` function, corresponding to `Lav_bufferLoadFromFile` in the C API, is merely convenience.
All that is required is to load the audio data into an array and call `buffer.load_from_array`.

==== Simple File Caching

If you care only about learning Libaudioverse, feel free to skip this section.

The following is a simple class extracted from one of my other projects.
It demonstrates the creation of a cache for files, such that they are loaded only once.

....
import libaudioverse
import os
import os.path

class SoundLoader(object):

    def __init__(self, simulation, sound_directory):
        self.simulation = simulation
        self.cache=dict()
        self.sound_directory = sound_directory

    def load_sound(self, key):
        #our sounds are ogg, so just add .ogg 
        if key not in self.cache:
            b = libaudioverse.Buffer(self.simulation)
            b.load_from_file(os.path.join(self.sound_directory, key+".ogg"))
            self.cache[key] = b
        b = self.cache[key]
        n = libaudioverse.BufferNode(self.simulation)
        n.buffer.value = b
        return n
....

To use it, instantiate the class with a simulation and call `load_sound` to get buffer nodes.
Libaudioverse does support other file formats, but you will almost always want to use `ogg` for size reasons.


Doing a loader like this  also allows tricks like grabbing files from the internet, decrypting, raeding from databases, or any number of other things limited only by imagination and time constraints.

=== Panning

The following are the required steps to wire a buffer node, here `buffer_player`, up for playback through an amplitude  panner.

....
panner=libaudioverse.AmplitudePanner(simulation)
buffer_player.connect(output = 0, node = panner, input = 0)
panner.connect_simulation(0)
....

Usually, the line with `.connect` does not use keyword arguments.
They are added here for clarity, but connecting is a very common operation.
The line `buffer_player.connect(0, panner, 0)` is exactly equivalent.

All panners have two properties of note, `azimuth` and `elevation`.
Both are measured in degrees.
Azimuth is the angle clockwise from the listener and elevation the angle between the horizontal and a line from the listener to the sound source.
Azimuth may be set to any value.
Elevation is constrained to be between -90 and 90.
Elevation is available on the amplitude panner for compatability with the HRTF panner, but otherwise has no effect.

This example introduces a node with inputs.
Inputs expect outputs to be connected to them.
If they don't have anything, they default to zero.
Failure to connect to the panner would be the same as panning a completely silent sound.
If you connect multiple outputs to the same input, they are added before being passed through the node.
If the same input is connected to multiple outputs, the audio is duplicated in the obvious manner.

Inputs and outputs  both have associated channel counts.
In most cases, Libaudioverse will do the right thing and convert between different channel counts appropriately.
You can find the specifics of such conversion <<basics-channels,here>>.


Nodes advance if  something needs them or if you specifically tell them to do so anyway.
If you are familiar with graph terminology or simply wish to see pseudocode of this algorithm, see the <<basics-audio-processing,section on audio processing>>.

